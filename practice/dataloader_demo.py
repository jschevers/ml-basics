# dataloader_demo.py
# PyTorch 1.5.0-CPU  Anaconda3-2020.02  
# Python 3.7.6  Windows 10 

import numpy as np
import torch as T
device = T.device("cpu")  # apply to Tensor or Module

# -----------------------------------------------------------

# predictors and label in same file
# data has been normalized and encoded like:
#   sex     age      region   income    politic
#   [0]     [2]       [3]      [6]       [7]
#   1 0   0.057143   0 1 0    0.690871    2

class PeopleDataset(T.utils.data.Dataset):

  def __init__(self, src_file, num_rows=None):
    x_tmp = np.loadtxt(src_file, max_rows=num_rows,
      usecols=range(0,7), delimiter="\t", skiprows=0,
      dtype=np.float32)
    y_tmp = np.loadtxt(src_file, max_rows=num_rows,
      usecols=7, delimiter="\t", skiprows=0, dtype=np.long)

    self.x_data = T.tensor(x_tmp, dtype=T.float32).to(device)
    self.y_data = T.tensor(y_tmp, dtype=T.long).to(device)

  def __len__(self):
    return len(self.x_data)  # required

  def __getitem__(self, idx):
    if T.is_tensor(idx):
      idx = idx.tolist()
    preds = self.x_data[idx, 0:7]
    pol = self.y_data[idx]
    sample = \
      { 'predictors' : preds, 'political' : pol }
    return sample

# -----------------------------------------------------------

def main():
  print("\nBegin PyTorch DataLoader demo ")

  # 0. misc. prep
  T.manual_seed(0)
  np.random.seed(0)

  print("\nSource data looks like: ")
  print("1 0  0.171429  1 0 0  0.966805  0")
  print("0 1  0.085714  0 1 0  0.188797  1")
  print(" . . . ")

  # 1. create Dataset and DataLoader object
  print("\nCreating Dataset and DataLoader ")

  train_file = ".\\people_train.txt"
  train_ds = PeopleDataset(train_file, num_rows=8)

  bat_size = 3
  train_ldr = T.utils.data.DataLoader(train_ds,
    batch_size=bat_size, shuffle=True)

  # 2. iterate thru training data twice
  for epoch in range(2):
    print("\n==============================\n")
    print("Epoch = " + str(epoch))
    for (batch_idx, batch) in enumerate(train_ldr):
      print("\nBatch = " + str(batch_idx))
      X = batch['predictors']  # [3,7]
      # Y = T.flatten(batch['political'])  # 
      Y = batch['political']   # [3]
      print(X)
      print(Y)
  print("\n==============================")

  print("\nEnd demo ")

  # vmport torchvision as tv
  # tform = tv.transforms.Compose([tv.transforms.ToTensor()])
  # mnist_train_ds = tv.datasets.MNIST(root=".\\MNIST_Data",
  #   train=True, transform=tform, target_transform=None,
  #   download=True)

  # mnist_train_dataldr = T.utils.data.DataLoader(mnist_train_ds,
  #   batch_size=2, shuffle=True)

  # for (batch_idx, batch) in enumerate(mnist_train_dataldr):
  #   print("")
  #   print(batch_idx)
  #   print(batch)
  #   input()  # pause

if __name__ == "__main__":
  main()

# source data in (tab-delimited) people_train.txt file:
#
# 1	0	0.171429	1	0	0	0.966805	0
# 0	1	0.085714	0	1	0	0.188797	1
# 1	0	0.000000	0	0	1	0.690871	2
# 1	0	0.057143	0	1	0	1.000000	1
# 0	1	1.000000	0	0	1	0.016598	2
# 1	0	0.171429	1	0	0	0.802905	0
# 0	1	0.171429	1	0	0	0.966805	1
# 1	0	0.257143	0	1	0	0.329876	0
